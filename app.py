import os
import streamlit as st
from dotenv import load_dotenv

load_dotenv()

# --- LangChain / OpenAI ---
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser


# =========================
# è¨­å®š
# =========================
# åˆ©ç”¨ãƒ¢ãƒ‡ãƒ«ã¯å¿…è¦ã«å¿œã˜ã¦å¤‰æ›´å¯ï¼ˆä¾‹: "gpt-4o-mini" / "gpt-4o"ï¼‰
LLM_MODEL = os.getenv("LLM_MODEL", "gpt-4o-mini")
TEMPERATURE = float(os.getenv("LLM_TEMPERATURE", "0.3"))

# å°‚é–€å®¶ãƒ­ãƒ¼ãƒ«ï¼ˆA/Bï¼‰
EXPERT_ROLES = {
    "Aï¼šè‹±èªæ•™å¸«": (
        "ã‚ãªãŸã¯çµŒé¨“è±Šå¯Œãªè‹±èªæ•™å¸«ã§ã™ã€‚"
        "ã‚ã‹ã‚Šã‚„ã™ã„èª¬æ˜ã¨ã‚·ãƒ³ãƒ—ãƒ«ãªä¾‹æ–‡ã‚’ç”¨ã„ã¦è§£èª¬ã—ã¦ãã ã•ã„ã€‚"
        "ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒæ—¥æœ¬èªã§å…¥åŠ›ã—ãŸå ´åˆã¯æ—¥æœ¬èªã§èª¬æ˜ã—ã¤ã¤ã€çŸ­ã„è‹±èªä¾‹æ–‡ã‚‚ç¤ºã—ã¦ãã ã•ã„ã€‚"
    ),
    "Bï¼šãƒãƒ¼ã‚±ãƒ†ã‚£ãƒ³ã‚°ã‚³ãƒ³ã‚µãƒ«ã‚¿ãƒ³ãƒˆ": (
        "ã‚ãªãŸã¯ãƒãƒ¼ã‚±ãƒ†ã‚£ãƒ³ã‚°ã®å°‚é–€ã‚³ãƒ³ã‚µãƒ«ã‚¿ãƒ³ãƒˆã§ã™ã€‚"
        "å®Ÿç”¨çš„ã§ã€æ®µéšçš„ã«å®Ÿè¡Œã§ãã‚‹ã‚¢ãƒ‰ãƒã‚¤ã‚¹ã‚’ç°¡æ½”ã«æä¾›ã—ã¦ãã ã•ã„ã€‚"
    ),
}

# --- LLM ã‚’ä½œæˆã™ã‚‹é–¢æ•° ---
def build_llm():
    return ChatOpenAI(model=LLM_MODEL, temperature=TEMPERATURE, streaming=False)

PROMPT = ChatPromptTemplate.from_messages(
    [
        ("system",
         "ã‚ãªãŸã¯ä»¥ä¸‹ã®å½¹å‰²ã‚’æŒã£ã¦å›ç­”ã—ã¾ã™ã€‚\n"
         "å½¹å‰²: {role_instructions}\n"
         "åˆ¶ç´„æ¡ä»¶:\n"
         "- å›ç­”ã¯ç°¡æ½”ã§å…·ä½“çš„ã«ã—ã¦ãã ã•ã„ã€‚\n"
         "- æ‰‹é †ã‚’æ±‚ã‚ã‚‰ã‚ŒãŸå ´åˆã¯ç•ªå·ä»˜ããƒªã‚¹ãƒˆã§ç¤ºã—ã¦ãã ã•ã„ã€‚\n"
         "- ä¸æ˜ãªå ´åˆã¯çŸ­ãç¢ºèªè³ªå•ã‚’ã—ã¦ãã ã•ã„ã€‚\n"),
        ("human", "{user_input}")
    ]
)

PARSER = StrOutputParser()


# =========================
# ä¸­æ ¸é–¢æ•°
# =========================
def generate_response(user_text: str, selected_role_key: str) -> str:
    llm = build_llm()
    chain = PROMPT | llm | PARSER
    role_instructions = EXPERT_ROLES[selected_role_key]
    result = chain.invoke({"role_instructions": role_instructions, "user_input": user_text})
    return result


# =========================
# Streamlit UI
# =========================
st.set_page_config(page_title="LLM å°‚é–€å®¶ãƒãƒ£ãƒƒãƒˆ", page_icon="ğŸ¤–", layout="centered")

st.title("ğŸ¤– LLM å°‚é–€å®¶ãƒãƒ£ãƒƒãƒˆ")
st.markdown(
    """
**ã‚¢ãƒ—ãƒªæ¦‚è¦**  
- å…¥åŠ›æ¬„ã«è³ªå•ã‚„ä¾é ¼ã‚’å…¥åŠ›ã™ã‚‹ã¨ã€é¸æŠã—ãŸã€Œå°‚é–€å®¶ã®å½¹å‰²ã€ã§ LLM ãŒå›ç­”ã—ã¾ã™ã€‚  
- å°‚é–€å®¶ã®ç¨®é¡ã¯ãƒ©ã‚¸ã‚ªãƒœã‚¿ãƒ³ã‹ã‚‰é¸ã¹ã¾ã™ï¼ˆA: è‹±èªæ•™å¸« / B: ãƒãƒ¼ã‚±ãƒ†ã‚£ãƒ³ã‚°ã‚³ãƒ³ã‚µãƒ«ã‚¿ãƒ³ãƒˆï¼‰ã€‚

**æ“ä½œæ–¹æ³•**  
1. å·¦ã®ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§ã€Œå°‚é–€å®¶ã®ç¨®é¡ã€ã‚’é¸æŠã—ã¦ãã ã•ã„  
2. ä¸‹ã®ãƒ†ã‚­ã‚¹ãƒˆã‚¨ãƒªã‚¢ã«è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„  
3. ã€Œé€ä¿¡ã€ã‚’æŠ¼ã™ã¨ã€å›ç­”ãŒè¡¨ç¤ºã•ã‚Œã¾ã™
    """
)

with st.sidebar:
    st.header("è¨­å®š")
    selected_role = st.radio("å°‚é–€å®¶ã‚’é¸ã‚“ã§ãã ã•ã„", list(EXPERT_ROLES.keys()), index=0)
    st.caption(f"ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«: `{LLM_MODEL}` / æ¸©åº¦: {TEMPERATURE}")

user_input = st.text_area("ã“ã“ã«è³ªå•ã‚„ä¾é ¼ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„", height=140, placeholder="ä¾‹ï¼šã“ã®è‹±æ–‡ã‚’ã‚„ã•ã—ãè§£èª¬ã—ã¦")
submitted = st.button("é€ä¿¡")

if submitted:
    if not user_input.strip():
        st.warning("è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
    else:
        try:
            with st.spinner("å›ç­”ã‚’ç”Ÿæˆã—ã¦ã„ã¾ã™â€¦"):
                answer = generate_response(user_input, selected_role)
            st.markdown("### å›ç­”")
            st.write(answer)
        except Exception as e:
            st.error(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸï¼š{e}")